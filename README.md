# PEC3_Manovich_Reloaded

**Autor**: Muñoz López, Manel
**Data**: 17/12/2023

## Introducció
Parlem d’hibridació de mitjans com al següent pas dels conceptes de remediació i multimèdia, que fusiona i combina els mitjans més enllà del multimèdia per generar un medi completament **nou** mitjançant la interacció d’aquests mitjans.

Als mitjans híbrids conflueixen llenguatges dels mitjans fusionats. Creant noves estructures i intercanviant propietats.  
  
A diferència del multimèdia on els continguts es consumeixen de manera seqüencial (l'un al costat de l'altre) i amb el visor corresponent de cada medi, a hibridació implica la integració i la interacció de múltiples mitjans digitals en una única plataforma generant una experiència d’usuari fluida, integrada i una nova manera de consumir i relacionar-nos amb els mitjans.
 

El concepte multimèdia defineix la confluència de continguts procedents de diferents mitjans però no dels seus llenguatges.

En els mitjans multimèdia trobem aplicacions i documents on conviuen de forma contigua i autònoma els diferents tipus de mitjans (gràfics, textos, sons, imatges, vídeos, escenes 3D).
-   Què és la hibridació de mitjans? (breument per introduir el document)
-   Com es pot reconèixer una d'aquestes hibridacions? Com distingir-ne d'altres (multimèdia/remediació)?
-   Cas escollit (Com funciona i mitjans que incorpora)
-   Quina mena d'hibridació es pot identificar en aquest cas? (segons Manovich)
-   Valoracions personals i bibliografia

##  Re-descobrint la hibridació: Google Translate

![File:Translate google.png - Wikimedia Commons](https://upload.wikimedia.org/wikipedia/commons/c/c4/Translate_google.png)
[CC-BY-SA-4.0](https://commons.wikimedia.org/wiki/Category:CC-BY-SA-4.0 "Category:CC-BY-SA-4.0")
Date: *12 July 2021*
Source: *translate google*
Author: *translate google*

Un exemple de l’evolució dels tres conceptes remediació, multimèdia i hibridació el trobaríem amb l’eina de traducció automàtica *Google Translate*. Eina multiplataforma que permet traduir webs i textos en 133 idiomes i una de les més emprades. La seva aplicació per Android té més de 1000 milions de descàrregues.  
  
En el moment del seu naixement l’any 2006, era una remediació digital dels diccionaris bilingües. Podies traduir paraules, frases en la seva interfície web. El text indicat primer s'havia de traduir a l’anglès abans de traduir-se a l’idioma seleccionat. En 2016 s'incorporarà un sistema de traducció automàtica neuronal substituint l’anterior mètode que traduïa frase a frase i paraula a paraula.
  
A partir del gener 2010, fa el salt als dispositius Android (als telèfons iOS arribarà un any més tard) I un mes després s’integrarà l’eina als navegadors Google Chrome i el més desatacat, ja té la capacitat de pronunciar el text traduït. És aquesta habilitat la que provoca el salt de ser una còpia digital dels clàssics diccionaris a ser un mitjà multimèdia. A part de tenir el significat de la traducció podem escolar la seva pronunciació.

 Aquesta etapa durarà fins al 2014, quan Google adquireix l'aplicació Word Lens que permetia la traducció visual i incorpora aquesta característica al seu traductor, permeten escanejar text o una imatge mitjançant el dispositiu mòbil i traduir-lo a l’instant per realitat augmentada, identificant automàticament l’idioma estranger. Encara que sembli que és una funció multimèdia, ja que introdueix un nou mitja com és la imatge, parlem d’hibridació perquè aquesta imatge s’integra en la traducció. No és un element independent, forma part de la interfície de l’aplicació. Reconfigura la traducció en una forma innovadora, integrant-la en la realitat.  
  

Però aquesta hibridació no es queda únicament amb la integració d’imatges capturades pels dispositius mòbils. L’aplicació fa el salt a diferents *wereables* com els altaveus intel·ligents (2019) o uns prototips d’ulleres (2022) on es permet la traducció simultània oral.

##  Re-descobrint la hibridació: Symphony | Experiència RV | CaixaForum Barcelona
Un altre exemple d’hibridació el podem trobar a Barcelona, concretament al centre CaixaForum on tenen un espai permanent d’experiències immersives audiovisuals. Actualment ofereixen dues experiències: El Bolero de Ravel i Symphony.


Vaig decantar-me per aquesta última dirigida per Igor Cortadellas  perquè em va cridar l’atenció la frase *”entendre la múscia clásica”* publicada al seu web: *“L'espectador podrà viure i entendre la música clàssica sentint-se com un músic més dins d'una orquestra. A través d'aquesta experiència única, gaudirà de les composicions de **Beethoven**, **Mahler** i **Bernstein**, gràcies al gran director d'orquestra **Gustavo Dudamel** i els més de 100 músics integrants de la prestigiosa **Mahler Chamber** Orchestra.”*

Una vegada en el centre d’exposicions, entrem en una sala similar a un cinema on expliquen en què l’experiència està formada en dues parts. Una primera serà en aquella mateixa sala on projectaran un vídeo introductori. La sala està equipada amb una pantalla panoràmica i so envolant. 
La projecció no és una introducció al món 360° i com funciona aquest sistema, sinó a l’argument i història que veurem a la segona part. I va ser sorprenent que amb dos mitjans multimèdia, com són el vídeo i el so, aconsegueix una sensació tan immersiva. Realment van captar la meva atenció i expectació per la següent fase.
Finalitzada la projecció, ens van passar a la següent sala, aquesta diferia completament d’una sala de projecció: Un faristol en mig de la sala amb un ordinador on es trobaven els  guies de l’activitat i envoltant-los, unes fileres de cadires separades entres elles i equipades amb auriculars i ulleres 3D. Després d’una breu explicació, ens posem els auriculars i les ulleres i desapareixem de la sala endinsa-nos a l’escenari del Liceu de Barcelona amb el director Gustavo Dudamel i la Mahler Chamber Orchestra.
Cal dir que va ser la meva primera experiència immersiva i les sensacions rebudes van ser molt sorprenents i diferents d'altres reproduccions multimèdia. Per aquest motiu el presento com un exemple d’hibridació. 
L'experiència està composta tant per àudio i vídeo filmat com generat per ordinador. Una combinació de mitjans habituals al món del cinema des de fa temps. *“The Abyss”*, de l’any 1989, i dirigida per James Cameron és la primera pel·lícula que inclou una simulació digital realista. Però el que canvia, tal com he comentat abans és la forma d'experimentar l’activitat. Hi ha escenes creades per ordinador que simulen estar dintre d’un instrument, que com que no hi ha cap punt de referència, sembla que estiguis flotant. Mirés a terra, però no veus la cadira ni les teves cames. L'únic element que et recordava que estaves en un món era la cadira que no permetia girar 360°. 

## Bibliografia i referències
